# ðŸ“¦ Data Modeling: Non-technical Explanation

In this project, we explore what causes delivery delays and operational risks in
a real-world logistics network operating in Southern California. The dataset includes
hourly data collected between 2021 and 2024 from trucks, rail, and warehouses. These
records reflect the conditions in which deliveries were madeâ€”whether that means
navigating through traffic, waiting at ports, or responding to equipment shortages.

To make sense of the dataset, we grouped the input features (variables) into three
broad categories:

- **Logistics Data**:-fuel usage, driver behavior, equipment status, and loading
  times
- **Environmental Factors**:-traffic congestion, weather conditions, port delays,
 and cargo condition
- **Economic & Operational Inputs**:-shipping costs, lead times, customs clearance
  duration, and supplier reliability

**Feature formats:**

- Binary variables (e.g., cargo status: 0 = bad, 1 = good)
- Scaled inputs (e.g., traffic levels: 0â€“10)
- Continuous measures (e.g., fuel in liters, shipping cost in USD)

Each row in the dataset is treated as a snapshot in time-representing a delivery
and the surrounding conditions at that moment.

## ðŸŽ¯ Target Variables

The goal is to describe what factors cause delivery delay and predict delivery
risk and delays before they occur. We model this through:

- **Delivery Time Deviation**:-how early or late a delivery is (in hours)
- **Risk Classification**:-Low, Moderate, or High
- **Delay Probability / Disruption Likelihood**:- values between 0 and 1

## âœ… Why This Model Works

### Interpretability

Each feature in the dataset corresponds directly to a real-world logistics factor,
such as traffic congestion, fuel consumption, or driver behavior. This connection
makes model outputs easier to explain and justify to decision-makers, because
the model is built on the same variables they already monitor and understand.

### Flexibility

The dataset is structured to support multiple types of machine learning tasks.
It can be used to train regression models that estimate delivery delays in hours,
classification models that categorize shipments by risk level. This dual-purpose
flexibility is ideal for real-world applications where different problems require
different modeling approaches.

### Real-Time Fit

Because the data is recorded on an hourly basis, it aligns well with how logistics
operations are managed in practice. Planners and dispatchers make decisions throughout
the day, and having time-stamped snapshots allows models to provide insights that
are both timely and actionable during live operations.

## ðŸ”„ Delivery Modeling Flow

![alt text](modeling_flow-2.png)

## Limitations of the Model

### Lacks Temporal Tracking

The dataset treats each shipment record as an isolated snapshot in time.
While this is useful for analysis, it limits the ability to understand how
a shipment's condition evolves hour by hour. Without tracking progression across
time steps, the model can miss trends or cascading delays.

### GPS-Only Location Data

Although the dataset includes precise latitude and longitude, it lacks contextual
location fields such as city, state, or route identifiers. This makes it harder to
analyze trends regionally or understand how geography affects delivery performance.

### No Product Type Information

All shipments are treated the same, regardless of whatâ€™s being delivered. However,
different types of cargoâ€”such as perishable food, electronics, or industrial
equipmentâ€”may be more or less sensitive to delays or environmental conditions. Without
this information, the model may overlook key risk differences.

### Simplified Model Assumptions

The modeling approach often assumes that relationships between inputs and outcomes
are clean and predictable (e.g., more traffic equals more delay). In reality, logistics
systems are highly interconnected and can exhibit non-linear behaviors that are
difficult to fully capture using static features alone.

### Limited Extreme Disruption Data

The dataset may not contain many examples of high-impact disruptions such as natural
disasters, labor strikes, or system-wide breakdowns. As a result, models trained
on this data may not perform well under rare but critical scenarios that demand
fast and accurate predictions.
