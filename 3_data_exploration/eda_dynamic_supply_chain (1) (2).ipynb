{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# üìä Exploratory Data Analysis (EDA): Supply Chain Logistics Dataset\n",
    "\n",
    "This notebook performs **Exploratory Data Analysis (EDA)** on a real-world supply chain logistics dataset. EDA is the foundation of any data-driven investigation. It helps us understand the **structure**, **patterns**, and **quality** of the data before applying any models, algorithms, or drawing conclusions.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Objectives of This Notebook\n",
    "\n",
    "- Load and preview the dataset\n",
    "- Clean and prepare data (without modifying original files)\n",
    "- Explore patterns through visualizations\n",
    "- Understand distributions and correlations\n",
    "- Surface operational, temporal, and spatial trends\n",
    "- Explore how different features relate to delivery delay and risk classification\n",
    "\n",
    "We strictly avoid modeling, statistical testing, or altering the source dataset at this stage.\n",
    "\n",
    "---\n",
    "\n",
    "### üìÅ Dataset Source\n",
    "\n",
    "This notebook uses a dataset located in the `0_datasets/` directory. Per project guidelines:\n",
    "\n",
    "- Do not modify the original data\n",
    "- Ensure all analysis is reproducible\n",
    "- Save outputs and visuals to this exploration folder if needed\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Reference Guide\n",
    "\n",
    "This analysis follows principles from:\n",
    "\n",
    "- **Chapter 4 - Exploratory Data Analysis**  \n",
    "  From *The Art of Data Science* by Roger D. Peng and Elizabeth Matsui\n",
    "\n",
    "> \"Exploratory analysis is not about testing a hypothesis. It's about allowing the data to reveal its structure, patterns, and surprises.\"\n",
    "\n",
    "---\n",
    "\n",
    "> **This is not modeling.**  \n",
    "> No inferential statistics or machine learning is performed here.  \n",
    "> This work is intended to prepare for those stages by grounding us in what the data is really saying.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Step 1: Initial Glimpse and Summary\n",
    "### ‚úÖ Data Preview\n",
    "\n",
    "- **Temporal**: timestamp\n",
    "- **Geospatial**: vehicle_gps_latitude, vehicle_gps_longitude\n",
    "- **Operational & Predictive**: fuel, delay, risk, congestion, equipment, etc.\n",
    "- **Target/Label**: risk_classification, delivery_time_deviation\n",
    "---\n",
    "### üìä Descriptive Summary\n",
    "\n",
    "- Most variables are numerical and will be great for correlation and trend analysis.\n",
    "- timestamp needs to be converted to a datetime format for time-based exploration.\n",
    "- Two categorical variables:\n",
    "  - timestamp (to be parsed)\n",
    "  - risk_classification\n",
    "---\n",
    "### ‚ö†Ô∏è Data Quality\n",
    "\n",
    "- **Missing values**: None (every column has 32,065 entries).\n",
    "- **Duplicate rows**: `0` duplicates found ‚Äì ‚úÖ clean!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset using raw string literal and fallback encoding\n",
    "df = pd.read_csv(r\"C:\\Users\\alema\\OneDrive\\Desktop\\DS_GroupProject\\dynamic_supply_chain_logistics_dataset.csv\", encoding='latin1')\n",
    "\n",
    "# Basic Structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic structure\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic structure\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning & Type Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Missing values heatmap\n",
    "plt.figure(figsize=(12, 1))\n",
    "sns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap=\"BuPu\")\n",
    "plt.title('Missing Data Overview')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Step 3: Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of numerical features\n",
    "for col in df.select_dtypes('float64').columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(df[col], bins=30, kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()\n",
    "\n",
    "# Categorical variable\n",
    "sns.countplot(x='risk_classification', data=df)\n",
    "plt.title('Distribution of Risk Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Step 4: Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=False, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Boxplots by risk classification\n",
    "features = ['fuel_consumption_rate', 'eta_variation_hours', 'shipping_costs', 'delay_probability']\n",
    "for col in features:\n",
    "    sns.boxplot(data=df, x='risk_classification', y=col)\n",
    "    plt.title(f'{col} by Risk Classification')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### üîó Multivariate Analysis Summary\n",
    "---\n",
    "#### 1. üìâ Correlation Heatmap\n",
    "\n",
    "**Strong Positive Correlations:**\n",
    "- delay_probability and delivery_time_deviation\n",
    "- shipping_costs and `warehouse_inventory_level\n",
    "\n",
    "**Strong Negative Correlations:**\n",
    "- driver_behavior_score and delay_probability\n",
    "- fatigue_monitoring_score and risk-related variables\n",
    "\n",
    "**These insights suggest operational behavior and fatigue are inversely tied to delay and disruption.**\n",
    "\n",
    "#### 2. üîç Pairwise Scatterplots\n",
    "\n",
    "**Observed Patterns:**\n",
    "- High delay_probability ‚Üí High delivery_time_deviation\n",
    "- eta_variation_hours and fuel_consumption_rate vary widely\n",
    "\n",
    "‚ö†Ô∏è Some non-linear relationships appear ‚Äî **feature engineering** may improve future models.\n",
    "\n",
    "#### 3. üì¶ Boxplots by `risk_classification`\n",
    "\n",
    "**Findings:**\n",
    "- **High Risk** trips have greater delay_probability and delivery_time_deviation`\n",
    "- **Shipping Costs** and **ETA Variation** are elevated in higher risk classes\n",
    "\n",
    "‚úÖ These differences validate that `risk_classification` reflects meaningful risk segmentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Step 5: Time Series Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Time Series Exploration\n",
    "\n",
    "# Create time-based features\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day'] = df['timestamp'].dt.day\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "\n",
    "# Time series trends: average delivery deviation and delay probability by month\n",
    "monthly_trends = df.groupby('month')[['delivery_time_deviation', 'delay_probability']].mean()\n",
    "\n",
    "# Plot monthly trends\n",
    "monthly_trends.plot(marker='o', figsize=(10, 5))\n",
    "plt.title('Monthly Averages: Delivery Deviation & Delay Probability')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Value')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Hourly trend: Average traffic congestion\n",
    "hourly_congestion = df.groupby('hour')['traffic_congestion_level'].mean()\n",
    "\n",
    "# Plot hourly congestion trend\n",
    "plt.figure(figsize=(10, 4))\n",
    "hourly_congestion.plot(marker='o')\n",
    "plt.title('Average Traffic Congestion by Hour of Day')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Traffic Congestion Level')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Daily variation: Average fuel consumption\n",
    "daily_fuel = df.groupby('day')['fuel_consumption_rate'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "daily_fuel.plot(marker='o')\n",
    "plt.title('Average Fuel Consumption by Day of Month')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Fuel Consumption Rate')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### üìÜ Monthly Trends\n",
    "\n",
    "- **Delivery Time Deviation** and **Delay Probability** tend to rise mid-year (peaking around summer months).\n",
    "- Possible **seasonality effects** (weather, demand surges, or vacation periods) may be influencing logistics delays.\n",
    "---\n",
    "### ‚è∞ Hourly Trends\n",
    "\n",
    "- **Traffic Congestion Level** is higher during typical rush hours (**8‚Äì10 AM** and **4‚Äì6 PM**).\n",
    "- Suggests congestion follows expected urban patterns and could inform **time-window planning**.\n",
    "---\n",
    "### üìÖ Daily Trends\n",
    "\n",
    "- **Fuel Consumption Rate** shows mild fluctuation day-to-day.\n",
    "- Could reflect varying **routes, cargo weights, or operational conditions**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Step 6: Spatial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPS Coordinates\n",
    "sns.scatterplot(x='vehicle_gps_longitude', y='vehicle_gps_latitude', hue='risk_classification', data=df, alpha=0.5)\n",
    "plt.title('Vehicle Locations by Risk Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Step 7: Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot by risk class for delivery_time_deviation\n",
    "sns.boxplot(x='risk_classification', y='delivery_time_deviation', data=df)\n",
    "plt.title('Delivery Time Deviation by Risk Classification')\n",
    "plt.show()\n",
    "\n",
    "# Correlations with delivery_time_deviation\n",
    "corrs = df.corr(numeric_only=True)['delivery_time_deviation'].sort_values(ascending=False)\n",
    "corrs.head(10).plot(kind='barh')\n",
    "plt.title('Top Correlations with Delivery Time Deviation')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## üìå Conclusion\n",
    "- No missing data or duplicates found.\n",
    "- Several strong correlations and temporal/spatial patterns.\n",
    "- `risk_classification` and `delivery_time_deviation` show meaningful relationships with operational variables.\n",
    "- This EDA sets a strong foundation for modeling or optimization work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
